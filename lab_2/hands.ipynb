{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnqyfI_nNxLO"
   },
   "source": [
    "# Если вы используется GoogleColab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfTwKD1ZOW1z"
   },
   "source": [
    "Не забудьте сменить среду выполнения на **GPU** - так программа будет работать быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FxOvRA3OG0O"
   },
   "source": [
    "Если вам удобнее загрузить данные непосредственно в сессионное хранилище, то ничего выполнять не нужно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWmLv2lwN6NZ"
   },
   "source": [
    "Если вам удобнее загрузить данные на гугл диск, то выполните следующие ячейки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aC-eLsxyN8fa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sf669wiON5yR"
   },
   "outputs": [],
   "source": [
    "cd drive/MyDrive\n",
    "# эта ячейка делает директорией по умолчанию ту директорию, в которой у вас расположены все файлы\n",
    "# или, говоря иначе, то место, в которое вы попадаете при открытии диска\n",
    "# если все данные программы лежат в какой-то папке под названием directory_name\n",
    "# то используется следующую команду: cd drive/MyDrive/directory_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHnwf22a368q"
   },
   "source": [
    "# Библиотеки и дополнительные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yWo66uc34Ita"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SJUJ5LR735Gf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg13\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TTF\n",
    "\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "import cv2 as cv\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from scipy.ndimage import binary_fill_holes as fill_holes\n",
    "from skimage.measure import moments_coords\n",
    "from skimage.measure import label, find_contours, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NsfrsCAm5DqR"
   },
   "outputs": [],
   "source": [
    "def angle_between(vec1, vec2):\n",
    "    \"\"\" \n",
    "    Угол между двумя векторами (в градусах)\n",
    "    \"\"\"\n",
    "    vec1_unit = vec1 / np.linalg.norm(vec1)\n",
    "    vec2_unit = vec2 / np.linalg.norm(vec2)\n",
    "    return np.arccos(np.clip(np.dot(vec1_unit, vec2_unit), -1, 1)) * 57.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STxQidra3-hV"
   },
   "source": [
    "# Реализация свёрточной нейронной сети UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gZGUVcOY3-64"
   },
   "outputs": [],
   "source": [
    "class VGG13Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_blocks, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.blocks = nn.ModuleList()\n",
    "        # Obtaining pretrained VGG model from torchvision.models and\n",
    "        # copying all layers except for max pooling.\n",
    "        feature_extractor = vgg13(pretrained=pretrained).features\n",
    "        for i in range(self.num_blocks):\n",
    "            self.blocks.append(\n",
    "                torch.nn.Sequential(*[\n",
    "                    feature_extractor[j]\n",
    "                    for j in range(i * 5, i * 5 + 4)\n",
    "                ])\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = []\n",
    "        for i in range(self.num_blocks):\n",
    "            x = self.blocks[i](x)\n",
    "            activations.append(x)\n",
    "            if i != self.num_blocks - 1:\n",
    "                x = torch.functional.F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JMGHC_g34BSe"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(torch.nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upconv = torch.nn.Conv2d(\n",
    "            in_channels=out_channels * 2, out_channels=out_channels,\n",
    "            kernel_size=3, padding=1, dilation=1\n",
    "        )\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=out_channels * 2, out_channels=out_channels,\n",
    "            kernel_size=3, padding=1, dilation=1\n",
    "        )\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=out_channels, out_channels=out_channels,\n",
    "            kernel_size=3, padding=1, dilation=1\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, down, left):\n",
    "        x = torch.nn.functional.interpolate(down, scale_factor=2)\n",
    "        x = self.upconv(x)\n",
    "        x = self.relu(self.conv1(torch.cat([left, x], 1)))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U_lXR2gf4BY5"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_filters, num_blocks):\n",
    "        super().__init__()\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            self.add_module(f'block{num_blocks - i}', DecoderBlock(num_filters * 2**i))\n",
    "\n",
    "    def forward(self, acts):\n",
    "        up = acts[-1]\n",
    "        for i, left in enumerate(acts[-2::-1]):\n",
    "            up = self.__getattr__(f'block{i + 1}')(up, left)\n",
    "        return up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kB8Ztm8d4Bbb"
   },
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes=1, num_filters=64, num_blocks=4):\n",
    "        super().__init__()\n",
    "        self.encoder = VGG13Encoder(num_blocks=num_blocks)\n",
    "        self.decoder = Decoder(num_filters=64, num_blocks=num_blocks - 1)\n",
    "        self.final = torch.nn.Conv2d(\n",
    "            in_channels=num_filters, out_channels=num_classes, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        acts = self.encoder(x)\n",
    "        x = self.decoder(acts)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcoRNqpd41rq"
   },
   "source": [
    "# Основная функция, выдающая результат работы программы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1T6bSIwc48yU"
   },
   "outputs": [],
   "source": [
    "def predict(model, path, filename, threshold=0.1):\n",
    "  # прочитаем изображение \n",
    "  image = cv.imread(path + '/' + filename)\n",
    "\n",
    "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "  model = model.to(device)\n",
    "  model.eval()\n",
    "\n",
    "  # произведем все необходимые трансформации\n",
    "  mean = [0.485, 0.456, 0.406]\n",
    "  std = [0.229, 0.224, 0.225]\n",
    "  totensor = transforms.ToTensor()\n",
    "  img = totensor(image)\n",
    "  img = F.pad(img, (1, 1, 1, 1))\n",
    "  img = TTF.resize(img, [704, 512])\n",
    "  img = img.unsqueeze(0)\n",
    "  normalize = transforms.Normalize(mean, std)\n",
    "  img = normalize(img)\n",
    "\n",
    "  img = img.to(device)\n",
    "  with torch.no_grad():\n",
    "    out = model(img).cpu()\n",
    "  \n",
    "  # получим результат работы нейросети\n",
    "  res = torch.sigmoid(out)\n",
    "\n",
    "  # получим маску, путем бинаризации\n",
    "  a = np.array(res.squeeze())\n",
    "  a[a < threshold] = 0\n",
    "  a[a >= threshold] = 255\n",
    "  a = a.astype(np.uint8)\n",
    "\n",
    "  # найдём все необходимые контуры в маске (их должно быть 9)\n",
    "  contours, hierarchy = cv.findContours(a, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # определим центры контуров, как центры масс\n",
    "  centers = []\n",
    "  for contour in contours:\n",
    "    if len(contour) >= 5:\n",
    "      M = moments_coords(contour.squeeze())\n",
    "      center = int(M[1, 0]/M[0, 0]), int(M[0, 1]/M[0, 0])\n",
    "      centers.append(center)\n",
    "\n",
    "  if len(centers) != 9:\n",
    "    print('Для изображения ' + name + ' не удалось корректно определить маску.')\n",
    "    return -1\n",
    "  \n",
    "  # переведем исходное изображение в черно-белое и отфильтруем\n",
    "  if image.shape != (702, 510, 3):\n",
    "    pil_image = Image.open(path + '/' + filename).convert('RGB') \n",
    "    pil_image = TTF.resize(pil_image, [704, 512])\n",
    "    open_cv_image = np.array(pil_image) \n",
    "    # Convert RGB to BGR \n",
    "    image = open_cv_image[:, :, ::-1].copy() \n",
    "  image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "  image_gray = cv.cvtColor(image_rgb, cv.COLOR_RGB2GRAY)\n",
    "  _, image_bin = cv.threshold(image_gray, 90, 255, cv.THRESH_BINARY)\n",
    "\n",
    "  # найдём центр руки\n",
    "  labeled_image = label(image_bin) \n",
    "  for component in regionprops(labeled_image): \n",
    "    if component.area > 35000: \n",
    "      center_ruki = tuple(map(int, component.centroid))\n",
    "      center_ruki = (center_ruki[1], center_ruki[0])\n",
    "  \n",
    "  # найдем расстояния между центром руки и всеми 9 точками\n",
    "  distances = []\n",
    "  for center in centers:\n",
    "    dist = np.sqrt((center[0] - center_ruki[0])**2 + (center[1] - center_ruki[1])**2)\n",
    "    distances.append(dist)\n",
    "  \n",
    "  distances = np.array(distances)\n",
    "  osnov = np.argsort(distances)[:4] # это номера перемычек в списке centers\n",
    "  paltsi = [] # это координаты пальцев\n",
    "  for i in np.argsort(distances)[4:]:\n",
    "    paltsi.append(centers[i])\n",
    "  \n",
    "  hands_bases = [] # это координаты перемычек\n",
    "  for i in osnov:\n",
    "    hands_bases.append(centers[i])\n",
    "  \n",
    "  # найдём попарные расстояния между всеми перемычками\n",
    "  base_dists = []\n",
    "  for base in hands_bases:\n",
    "    tmp = []\n",
    "    for base_ in hands_bases:\n",
    "      dist = np.sqrt((base[0] - base_[0])**2 + (base[1] - base_[1])**2)\n",
    "      if dist != 0:\n",
    "        tmp.append((dist, base, base_))\n",
    "    base_dists.append(tmp)\n",
    "  \n",
    "  # максимальное из этих расстояний будет соответствовать большой перемычке\n",
    "  maximum = 0\n",
    "  big_base = None\n",
    "  for i in base_dists:\n",
    "    tmp = 0\n",
    "    for j in i:\n",
    "      tmp += j[0]\n",
    "    if tmp > maximum:\n",
    "      maximum = tmp\n",
    "      big_base = j[1]\n",
    "      big_base_dists = i\n",
    "  \n",
    "  base_dists = []\n",
    "  for base in hands_bases:\n",
    "    dist = np.sqrt((big_base[0] - base[0])**2 + (big_base[1] - base[1])**2)\n",
    "    if dist != 0:\n",
    "      base_dists.append((dist, base))\n",
    "\n",
    "  base_dict = {} # это словарь перемычек\n",
    "  base_dict[0] = big_base \n",
    "  for i, j in enumerate(sorted(base_dists)):\n",
    "    base_dict[i+1] = j[1]\n",
    "  \n",
    "  # находим большой палец\n",
    "  dists = []\n",
    "  for palets in paltsi:\n",
    "    dist = np.sqrt((base_dict[0][0] - palets[0])**2 + (base_dict[0][1] - palets[1])**2)\n",
    "    dists.append((dist, palets))\n",
    "  big_thumb = sorted(dists)[0][1]\n",
    "\n",
    "  # находим мизинец\n",
    "  dists = []\n",
    "  for palets in paltsi:\n",
    "    dist = np.sqrt((base_dict[3][0] - palets[0])**2 + (base_dict[3][1] - palets[1])**2)\n",
    "    dists.append((dist, palets))\n",
    "  mizinec = sorted(dists)[0][1]\n",
    "\n",
    "  # находим безымянный\n",
    "  dists = []\n",
    "  for palets in paltsi:\n",
    "    dist = np.sqrt((mizinec[0] - palets[0])**2 + (mizinec[1] - palets[1])**2)\n",
    "    if dist != 0:\n",
    "      dists.append((dist, palets))\n",
    "  bezimyaniy = sorted(dists)[0][1]\n",
    "\n",
    "  # находим указательный\n",
    "  dists = []\n",
    "  for palets in paltsi:\n",
    "    if palets != mizinec:\n",
    "      dist = np.sqrt((big_thumb[0] - palets[0])**2 + (big_thumb[1] - palets[1])**2)\n",
    "      if dist != 0:\n",
    "        dists.append((dist, palets))\n",
    "  ukazatelniy = sorted(dists)[0][1]\n",
    "\n",
    "  # находим средний путём исключения\n",
    "  for palets in paltsi:\n",
    "    if palets != big_thumb and palets != ukazatelniy and palets != mizinec and palets != bezimyaniy:\n",
    "      sredniy = palets\n",
    "  \n",
    "  # словарь пальцев\n",
    "  hands_dict = {0: big_thumb, 1: ukazatelniy, 2: sredniy, 3: bezimyaniy, 4: mizinec}\n",
    "\n",
    "  # подсчет углов между пальцами\n",
    "  angles = []\n",
    "  for base, hand in enumerate(range(len(hands_dict)-1)):\n",
    "    vec1 = np.array(hands_dict[hand]) - np.array(base_dict[base])\n",
    "    vec2 = np.array(hands_dict[hand+1]) - np.array(base_dict[base])\n",
    "    angles.append(angle_between(vec1, vec2))\n",
    "  # print(angles)\n",
    "\n",
    "  # подсчет результата\n",
    "  s = ''\n",
    "  for i in range(len(angles)):\n",
    "    # если палец большой\n",
    "    if i == 0:\n",
    "      if angles[i] < 27.5:\n",
    "        s += f'{i+1}+'\n",
    "      else:\n",
    "        s += f'{i+1}-'\n",
    "    elif i == 3:\n",
    "      if angles[i] < 20:\n",
    "        s += f'{i+1}+'\n",
    "      else:\n",
    "        s += f'{i+1}-'\n",
    "    else:\n",
    "      if angles[i] < 16.5:\n",
    "          s += f'{i+1}+'\n",
    "      else:\n",
    "          s += f'{i+1}-'\n",
    "  s += '5'\n",
    "\n",
    "  image_rgb = cv.putText(image_rgb, s, (10,40), cv.FONT_HERSHEY_PLAIN, 3, (251, 255, 0), 2, cv.LINE_AA)\n",
    "  cv.line(image_rgb, big_thumb, base_dict[0], (0,255,0), 2)\n",
    "  cv.line(image_rgb, base_dict[0], ukazatelniy, (0,255,0), 2)\n",
    "  cv.line(image_rgb, ukazatelniy, base_dict[1], (0,255,0), 2)\n",
    "  cv.line(image_rgb, base_dict[1], sredniy, (0,255,0), 2)\n",
    "  cv.line(image_rgb, sredniy, base_dict[2], (0,255,0), 2)\n",
    "  cv.line(image_rgb, base_dict[2], bezimyaniy, (0,255,0), 2)\n",
    "  cv.line(image_rgb, bezimyaniy, base_dict[3], (0,255,0), 2)\n",
    "  cv.line(image_rgb, base_dict[3], mizinec, (0,255,0), 2)\n",
    "  cv.imwrite('res/res_' + name[:-4] + '.png', cv.cvtColor(image_rgb, cv.COLOR_BGR2RGB))\n",
    "\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.title('Результат для ' + name, fontsize=14)\n",
    "  plt.imshow(image_rgb)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "  return hands_dict, base_dict, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz8UGYs04Fq9"
   },
   "source": [
    "# Основная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muwe8fyD4nXJ"
   },
   "source": [
    "Для начала загрузим обученную модель\n",
    "\n",
    "P.S.: здесь дополнительно скачиваются данные размером около 500MB, поэтому эта ячейка может выполняться дольше обычного (если совсем долго, можно попробовать перезапустить ядро)\n",
    "\n",
    "P.S.S: в GoogleColab она выполняется быстро :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model.load_state_dict(torch.load('model.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2noXeU8c5guU"
   },
   "source": [
    "Считаем названия всех файлов из папки Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rTZABM-d5ipq"
   },
   "outputs": [],
   "source": [
    "PATH = 'Samples'\n",
    "tmp = sorted(os.listdir(PATH))\n",
    "names = []\n",
    "for name in tmp:\n",
    "    if name.endswith(\".tif\"):\n",
    "        names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По желанию, можно вывести исходные изображения, запустив ячейку ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    image = cv.imread(PATH + '/' + name)\n",
    "    image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(name, fontsize=14)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPARjLXf5sH3"
   },
   "source": [
    "Узнаем результат!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Results.txt', 'w')\n",
    "for name in names:\n",
    "  res = predict(model, PATH, name)\n",
    "  if res != -1:\n",
    "    f.write(res[2] + '\\n')\n",
    "    s = '!,' + name + ','\n",
    "    for hand in res[0].values():\n",
    "      s += 'T ' + str(hand[0]) + ' ' + str(hand[1]) + ','\n",
    "    for base in res[1].values():\n",
    "      s += 'V ' + str(base[0]) + ' ' + str(base[1]) + ','\n",
    "    s += '?'\n",
    "    f.write(s + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hands.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
